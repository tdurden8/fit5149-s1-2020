{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Nonlinear models\n",
    "\n",
    "The materials used in this tutorial are based on the applied exercises provided in the book \"An Introduction to Statistical Learning with Applications in R\" (ISLR). We are trying to demonstrate how to implement the following nonlinear models:\n",
    "* Polynomial regression\n",
    "* Regression spline\n",
    "* Generalized additive model\n",
    "\n",
    "Even though you will learn how to use the above methods, it still is worth trying by yourself\n",
    "    1. Section 7.8 in the textbook\n",
    "\n",
    "\n",
    "## 1. Predict nitrogen oxides concentration in Boston\n",
    "This question uses the variables <font color=\"brown\">dis</font> (the weighted mean of distances to five Boston employment centers) and <font color=\"brown\">nox</font> (nitrogen oxides concentration in parts per 10 million) from the <font color=\"brown\">Boston</font> data. We will treat <font color=\"brown\">dis</font> as the predictor and <font color=\"brown\">nox</font> as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Fit a polynomial regression model\n",
    "Use the <font color=\"blue\">poly()</font> function to fit a cubic polynomial regression to predict <font color=\"brown\">nox</font> using <font color=\"brown\">dis</font>. Report the regression output, and plot the resulting data and polynomial fits. If you are not familiar with the poly() function, remember to use the help() function to print out its usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can follow the lab in section 7.8.1 to fit a simple polynomial regression model with degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "poly.fit <- \n",
    "summary(poly.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we have done with linear regression models, we can diagnose the model by looking at the summary. The p-value indicates that all the polynomial terms are significantly associated with the predictor. In order to see some differences, you can fit a polynomial model with degree 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find that it is still that the first three polynomial terms are significant.\n",
    "\n",
    "Next, let's plot the fitted curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dislims <- range(Boston$dis)\n",
    "dis.grid <- seq(from = dislims[1], to = dislims[2], by = 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Compare the polynomial models with different degrees.\n",
    "Plot the polynomial fits for a range of different polynomial degrees (say, from 1 to 10), and report the associated residual sum of squares. Here you need to generate one figure, where RSS is ploted as a function of polynomial degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rss <- rep(NA, 10)\n",
    "for (i in 1:10) {\n",
    "   \n",
    "    \n",
    "}\n",
    "plot(1:10, rss, xlab = \"Degree\", ylab = \"RSS\", type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3 Cross-validate the polynomial degree\n",
    "Perform cross-validation to select the optimal degree for the polynomial, and explain your results. Here, you are going to implement a 10-fold cross validation to pick the best polynomial regression model. You can use the <font color=\"blue\">cv.glm()</font> function in the <font color=\"brown\">boot</font> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require(splines)\n",
    "library(ISLR)\n",
    "library(boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deltas <- rep(NA, 10)\n",
    "for (i in 1:10) {\n",
    "\n",
    "    \n",
    "}\n",
    "plot(1:10, deltas, xlab = \"Degree\", ylab = \"Test MSE\", type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 10-fold CV shows that the CV error reduces as we increase degree from 1 to 3, stay almost constant till degree 5, and the starts increasing for higher degrees. We pick 4 as the best polynomial degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.4 Fit a regression spline\n",
    "\n",
    "Use the <font color=\"blue\">bs()</font> function to fit a regression spline to predict <font color=\"brown\">nox</font> using <font color=\"brown\">dis</font>. Report the output for the fit using four degrees of freedom. How did you choose the knots ? Plot the resulting fit. Examples about how to use the <font color=\"blue\">bs()</font> function can be found in section 7.8.2.\n",
    "\n",
    "We see that <font color=\"brown\">dis</font> has limits of about 1 and 13 respectively. (You can use the summary() function to print out the min, max, mean, median, etc) We split this range in roughly equal 4 intervals and establish knots at $[4, 7, 11]$. Note: bs function in R expects either df or knots argument. If both are specified, knots are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs.fit <-\n",
    "summary(rs.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary shows that all terms in spline fit are significant.\n",
    "Now, we can plot the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that the spline fits data well except at the extreme values of $dis$, (especially $dis > 10$).\n",
    "\n",
    "### 1.5 Fit a set of splines with different degrees of freedom.\n",
    "\n",
    "Now fit a regression spline for a range of degrees of freedom, and plot the resulting fits and report the resulting RSS. Describe the results obtained. \n",
    "\n",
    "We fit regression splines with dfs between 3 and 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rss <- rep(NA, 16)\n",
    "for (i in 3:16) {\n",
    "\n",
    "}\n",
    "plot(3:16, rss[-c(1, 2)], xlab = \"Degrees of freedom\", ylab = \"RSS\", type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RSS monotonically decreases till df=14 and then slightly increases for df=15 and df=16. Now, we need to select the best degree of freedom. \n",
    "\n",
    "### 1.6 Cross-validate the degree of freedom in regression spline\n",
    "\n",
    "Perform cross-validation in order to select the best degrees of freedom for a regression spline on this data. Describe your results. As what we did 1.3, we are going to use 10-fold cross-validation. (Note ignore the warning messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv <- rep(NA, 16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, visualize the CV errors by plotting Test MSE against the degree of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(3:16, cv[-c(1, 2)], xlab = \"Degrees of freedom\", ylab = \"Test MSE\", type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV error is more jumpy in this case, but attains minimum at df=10. We pick $10$ as the optimal degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Generalized additive model\n",
    "\n",
    "In this exercise, we are going to learn how to fit a GAM model to predict the out-of-state tuition on the <font color = \"brown\">College</font> data set. We start with splitting the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "set.seed(1)\n",
    "attach(College)\n",
    "train <- sample(length(Outstate), length(Outstate) / 2)\n",
    "test <- -train\n",
    "College.train <- College[train, ]\n",
    "College.test <- College[test, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Perform forward stepwise selection\n",
    "Using out-of-state tuition as the response and the other variables as the predictors, perform forward stepwise selection on the training set in order to identify a satisfactory  model that uses just a subset of the predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit <- \n",
    "fit.summary <- summary(fit)\n",
    "fit.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot $C_p$, BIC and adjusted-$R^2$ scores in order to identify a satisfactory model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(1, 3))\n",
    "plot(fit.summary$cp, xlab = \"Number of variables\", ylab = \"Cp\", type = \"l\")\n",
    "min.cp <- min(fit.summary$cp)\n",
    "std.cp <- sd(fit.summary$cp)\n",
    "abline(h = min.cp + 0.2 * std.cp, col = \"red\", lty = 2)\n",
    "abline(h = min.cp - 0.2 * std.cp, col = \"red\", lty = 2)\n",
    "plot(fit.summary$bic, xlab = \"Number of variables\", ylab = \"BIC\", type='l')\n",
    "min.bic <- min(fit.summary$bic)\n",
    "std.bic <- sd(fit.summary$bic)\n",
    "abline(h = min.bic + 0.2 * std.bic, col = \"red\", lty = 2)\n",
    "abline(h = min.bic - 0.2 * std.bic, col = \"red\", lty = 2)\n",
    "plot(fit.summary$adjr2, xlab = \"Number of variables\", ylab = \"Adjusted R2\", type = \"l\", ylim = c(0.4, 0.84))\n",
    "max.adjr2 <- max(fit.summary$adjr2)\n",
    "std.adjr2 <- sd(fit.summary$adjr2)\n",
    "abline(h = max.adjr2 + 0.2 * std.adjr2, col = \"red\", lty = 2)\n",
    "abline(h = max.adjr2 - 0.2 * std.adjr2, col = \"red\", lty = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_p$, BIC and adjusted-$R^2$ show that size 6 is the minimum size for the subset for which the scores\n",
    "are within 0.2 standard deviations of optimum. We pick 6 as the best subset size and find best 6 variables using entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit <- regsubsets(Outstate ~ ., data = College, method = \"forward\")\n",
    "coeffs <- coef(fit, id = 6)\n",
    "names(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Fit a GAM\n",
    "Fit a GAM on the training data, using out-of-state tuition as the response and the features selected in the previous step as the predictors. Plot the results, and explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require(gam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use smooth spline as the feature function, which can be implemented by using the <font color=\"blue\">s()</font> function in the <font color=\"brown\">gam</font> library. We use a step function to handle the <font color=\"brown\">Private</font>, use 5 degrees of freedome for <font color=\"brown\">Expend</font> variable and 2 for the other varaibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gam.fit <- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to produce similar plots as shown in Figure 7.12 in the textbook, we simply call the <font color=\"blue\">plot()</font> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(2, 3))\n",
    "plot(gam.fit, se = T, col = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model evaluation\n",
    "\n",
    "Evaluate the model obtained on the test set, and explain the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gam.preds <- \n",
    "gam.err <- \n",
    "gam.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the test $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gam.tss = mean((College.test$Outstate - mean(College.test$Outstate))^2)\n",
    "test.rss = 1 - gam.err/gam.tss\n",
    "test.rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a test R-squared of 0.77 using GAM with 6 predictors. This is a slight improvement over a test RSS of 0.74 obtained using OLS.\n",
    "\n",
    "For which variables, if any, is there evidence of a non-linear relationship with the response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(gam.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Non-parametric Anova test shows a strong evidence of non-linear relationship between response and Expend, and a moderately strong non-linear relationship (using p value of 0.05) between response and Grad.Rate or PhD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
